# üìä Instrumentaci√≥n de Performance - Gu√≠a de Uso

Este documento explica c√≥mo usar la instrumentaci√≥n de performance implementada en el backend para medir y analizar el rendimiento de los endpoints.

---

## üéØ ¬øQu√© est√° instrumentado?

Los siguientes 5 endpoints principales est√°n instrumentados con medici√≥n autom√°tica de tiempos:

1. **`GET /metrics/cards`** - M√©tricas generales del dashboard
2. **`GET /metrics/disciplinas`** - M√©tricas por disciplina (50-59)
3. **`GET /metrics/subsistemas`** - M√©tricas por subsistema
4. **`GET /metrics/changes/summary`** - Resumen de cambios entre cargas
5. **`GET /aconex/duplicates`** - Documentos duplicados en ACONEX

---

## üìã Endpoints de Administraci√≥n

### 1. Ver Estad√≠sticas de Performance

**Endpoint:** `GET /admin/performance/stats`

**Descripci√≥n:** Obtiene estad√≠sticas detalladas de todos los endpoints instrumentados o uno espec√≠fico.

**Par√°metros:**
- `endpoint` (opcional): Nombre del endpoint espec√≠fico (ej: `metrics_cards`)

**Ejemplos:**

```bash
# Ver estad√≠sticas de todos los endpoints
GET /admin/performance/stats

# Ver estad√≠sticas de un endpoint espec√≠fico
GET /admin/performance/stats?endpoint=metrics_cards
```

**Respuesta:**
```json
{
  "success": true,
  "stats": {
    "metrics_cards": {
      "calls": 5,
      "total_time_ms": 2450.5,
      "avg_time_ms": 490.1,
      "min_time_ms": 450.2,
      "max_time_ms": 520.8,
      "last_execution_queries": [
        {
          "description": "Count APSA ABIERTOS",
          "time_ms": 45.3
        },
        {
          "description": "Count APSA CERRADOS",
          "time_ms": 42.1
        },
        ...
      ]
    }
  },
  "note": "Tiempos en milisegundos (ms)"
}
```

---

### 2. Resumen Simplificado

**Endpoint:** `GET /admin/performance/summary`

**Descripci√≥n:** Retorna un resumen simplificado de los 5 endpoints principales, ideal para dashboards.

**Ejemplo:**
```bash
GET /admin/performance/summary
```

**Respuesta:**
```json
{
  "success": true,
  "summary": [
    {
      "endpoint": "metrics_cards",
      "avg_time_ms": 490.1,
      "min_time_ms": 450.2,
      "max_time_ms": 520.8,
      "calls": 5,
      "last_execution": {
        "query_count": 5,
        "total_query_time_ms": 450.0,
        "overhead_ms": 40.1
      }
    },
    ...
  ],
  "note": "Tiempos en milisegundos (ms). 'overhead_ms' = tiempo no gastado en queries SQL"
}
```

**Interpretaci√≥n:**
- `avg_time_ms`: Tiempo promedio total del endpoint
- `query_count`: N√∫mero de queries SQL ejecutadas
- `total_query_time_ms`: Tiempo total gastado en queries SQL
- `overhead_ms`: Tiempo gastado en procesamiento Python (no SQL)

---

### 3. Resetear Estad√≠sticas

**Endpoint:** `POST /admin/performance/reset`

**Descripci√≥n:** Limpia todas las estad√≠sticas acumuladas. √ötil despu√©s de pruebas o para empezar fresh.

**Ejemplo:**
```bash
POST /admin/performance/reset
```

**Respuesta:**
```json
{
  "success": true,
  "message": "Performance statistics reset successfully"
}
```

---

## üîç C√≥mo Leer los Logs

Cuando llamas a un endpoint instrumentado, ver√°s logs como estos:

```
============================================================
üöÄ START: metrics_cards
============================================================
  üìä Query #1: Count APSA ABIERTOS
     ‚è±Ô∏è  Completed in 45.30ms
  üìä Query #2: Count APSA CERRADOS
     ‚è±Ô∏è  Completed in 42.10ms
  üìä Query #3: Count ACONEX total rows
     ‚è±Ô∏è  Completed in 38.50ms
  ...
============================================================
‚úÖ END: metrics_cards - Total: 490.10ms (0.490s)
============================================================
```

**Elementos:**
- `üöÄ START`: Inicio del endpoint
- `üìä Query #N`: Cada query SQL individual
- `‚è±Ô∏è Completed in`: Tiempo que tard√≥ esa query
- `‚úÖ END`: Tiempo total del endpoint

---

## üìà Proceso de Medici√≥n (Workflow Recomendado)

### Paso 1: Resetear estad√≠sticas
```bash
POST /admin/performance/reset
```

### Paso 2: Ejecutar los endpoints que quieres medir
```bash
# Ejecuta cada endpoint varias veces para obtener un promedio confiable
GET /metrics/cards
GET /metrics/disciplinas
GET /metrics/subsistemas
GET /metrics/changes/summary
GET /aconex/duplicates
```

### Paso 3: Ver el resumen
```bash
GET /admin/performance/summary
```

### Paso 4: Analizar detalles de endpoints lentos
```bash
# Si metrics_disciplinas es lento:
GET /admin/performance/stats?endpoint=metrics_disciplinas
```

---

## üé® Interpretaci√≥n de Resultados

### Ejemplo: `/metrics/disciplinas`

Si ves algo como:
```json
{
  "endpoint": "metrics_disciplinas",
  "avg_time_ms": 3500,
  "last_execution": {
    "query_count": 40,
    "total_query_time_ms": 3200,
    "overhead_ms": 300
  }
}
```

**Diagn√≥stico:**
- ‚úÖ Total: 3.5 segundos (3500ms)
- ‚ö†Ô∏è 40 queries SQL (problema N+1)
- ‚úÖ 3.2 segundos en queries, 0.3 en overhead (91% en SQL)

**Conclusi√≥n:** El problema est√° en el n√∫mero de queries (40), no en la eficiencia individual de cada una.

---

### Ejemplo: `/metrics/cards`

Si ves:
```json
{
  "endpoint": "metrics_cards",
  "avg_time_ms": 800,
  "last_execution": {
    "query_count": 5,
    "total_query_time_ms": 750,
    "overhead_ms": 50
  }
}
```

**Diagn√≥stico:**
- ‚úÖ Total: 0.8 segundos (800ms)
- ‚úÖ 5 queries (razonable)
- ‚ö†Ô∏è 750ms en queries (cada query promedia 150ms)

**Conclusi√≥n:** Posible problema con subconsultas EXISTS o normalizaci√≥n en runtime.

---

## üö® Se√±ales de Alerta

### üî¥ Problema N+1
- `query_count` muy alto (>20 queries)
- Ejemplo: `/metrics/disciplinas` con 40 queries

**Soluci√≥n:** Reemplazar loops por GROUP BY

---

### üü† Queries lentas individuales
- Una sola query tarda >200ms
- `total_query_time_ms` alto pero `query_count` bajo

**Soluci√≥n:** Agregar √≠ndices o optimizar subconsultas

---

### üü° Alto overhead
- `overhead_ms` representa >30% del tiempo total
- Mucho procesamiento en Python

**Soluci√≥n:** Mover l√≥gica a SQL o cachear resultados

---

## üõ†Ô∏è C√≥mo Agregar Instrumentaci√≥n a Nuevos Endpoints

Si quieres instrumentar un nuevo endpoint:

### 1. Agregar decorador al endpoint
```python
from .timing import measure_endpoint, measure_query

@app.get("/mi-nuevo-endpoint")
@measure_endpoint("mi_nuevo_endpoint")
def mi_nuevo_endpoint(db: Session = Depends(get_db)):
    # ...
```

### 2. Envolver queries SQL
```python
with measure_query("Descripci√≥n de la query", "mi_nuevo_endpoint"):
    result = db.execute(query).scalar()
```

### 3. Verificar logs
```bash
# Revisar logs de la aplicaci√≥n
tail -f logs/app.log
```

---

## üìä M√©tricas de Baseline (ANTES de optimizar)

Despu√©s de implementar la instrumentaci√≥n, documenta los tiempos actuales como baseline:

| Endpoint | Queries | Tiempo Actual | Objetivo |
|----------|---------|---------------|----------|
| `/metrics/cards` | 5-8 | ? ms | <300ms |
| `/metrics/disciplinas` | 40 | ? ms | <500ms |
| `/metrics/subsistemas` | 2 | ? ms | <200ms |
| `/metrics/changes/summary` | 2 | ? ms | <300ms |
| `/aconex/duplicates` | 1 | ? ms | <200ms |

**TODO:** Completa esta tabla despu√©s de ejecutar tus endpoints con datos reales.

---

## üéØ Pr√≥ximos Pasos

1. ‚úÖ **Instrumentaci√≥n completada** (este documento)
2. ‚è≠Ô∏è **Medir baseline** con datos de producci√≥n
3. ‚è≠Ô∏è **Implementar optimizaciones** por etapas
4. ‚è≠Ô∏è **Medir mejoras** despu√©s de cada etapa
5. ‚è≠Ô∏è **Documentar resultados** finales

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Cambiar nivel de logging

En `backend/app/main.py`, l√≠nea 108:

```python
logging.basicConfig(
    level=logging.INFO,  # Cambiar a logging.DEBUG para m√°s detalle
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

**Niveles disponibles:**
- `logging.DEBUG`: M√°ximo detalle
- `logging.INFO`: Informaci√≥n normal (recomendado)
- `logging.WARNING`: Solo warnings y errores
- `logging.ERROR`: Solo errores

---

## üìû Soporte

Si tienes problemas con la instrumentaci√≥n:

1. Verifica que el logging est√© configurado correctamente
2. Revisa que los endpoints est√©n decorados con `@measure_endpoint`
3. Verifica que las queries usen `with measure_query(...)`
4. Revisa los logs de la aplicaci√≥n para errores

---

**√öltima actualizaci√≥n:** 2025-11-17
