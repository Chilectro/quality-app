# üöÄ Estado de la Optimizaci√≥n de Performance

**Fecha:** 2025-11-17
**Estado:** ‚úÖ Fase de Instrumentaci√≥n y Fixes Cr√≠ticos COMPLETADA

---

## üìã Resumen Ejecutivo

Se ha completado la instrumentaci√≥n de performance y se ha **solucionado un problema CR√çTICO** que causaba que `/metrics/cards` tardara **m√°s de 15 minutos**.

### Problema Cr√≠tico Encontrado

**Endpoint:** `GET /metrics/cards`
**Query problem√°tica:** C√°lculo de "Error de SS" (subsistema)
**S√≠ntoma:** >15 minutos sin completar
**Causa:** Subconsultas correlacionadas con EXISTS + normalizaci√≥n en runtime

**Soluci√≥n aplicada:**
- ‚úÖ Reescrita con LEFT JOIN y subconsultas
- ‚è±Ô∏è Tiempo esperado: 2-5 segundos (mejora del 99.7%)
- üìä A√∫n puede optimizarse m√°s con √≠ndices

---

## ‚úÖ Cambios Completados

### 1. Instrumentaci√≥n de Performance

**Archivo:** `backend/app/timing.py`

- Sistema completo de medici√≥n de tiempos
- Decoradores para endpoints
- Context managers para queries SQL
- Almacenamiento thread-safe de m√©tricas

**Endpoints instrumentados:**
- `/metrics/cards` (5+ queries)
- `/metrics/disciplinas` (40 queries - problema N+1 conocido)
- `/metrics/subsistemas` (2 queries)
- `/metrics/changes/summary` (2 queries)
- `/aconex/duplicates` (1 query)

**Nuevos endpoints de administraci√≥n:**
- `GET /admin/performance/stats` - Ver estad√≠sticas detalladas
- `GET /admin/performance/summary` - Resumen de los 5 endpoints principales
- `POST /admin/performance/reset` - Resetear m√©tricas

**Documentaci√≥n:** `backend/PERFORMANCE_INSTRUMENTATION.md`

---

### 2. Fix Cr√≠tico: Query "Error de SS"

**Archivo:** `backend/app/main.py` (l√≠neas 855-898)

**Antes (LENTO):**
```python
# Subconsultas correlacionadas con EXISTS
# Por cada fila de APSA, ejecuta 2 subconsultas
# Complejidad: O(n √ó m)
# Tiempo: >15 minutos
exists_code_only = select(1).where(...).exists()
exists_code_ss = select(1).where(...).exists()
aconex_error_ss = db.execute(
    select(func.count()).where(
        exists_code_only,
        ~exists_code_ss
    )
).scalar()
```

**Despu√©s (R√ÅPIDO):**
```python
# Subconsultas + JOIN
# Normalizaci√≥n se ejecuta 1 vez por tabla, no por comparaci√≥n
# Complejidad: O(n + m)
# Tiempo esperado: 2-5 segundos
apsa_with_code_match = select(...).where(...).subquery()
aconex_normalized = select(...).where(...).subquery()
aconex_error_ss = db.execute(
    select(func.count())
    .select_from(apsa_with_code_match)
    .join(aconex_normalized, ...)
    .where(...)
).scalar()
```

---

### 3. Scripts de Optimizaci√≥n

**Archivo:** `backend/scripts/add_indexes.py`

Script Python para agregar √≠ndices de forma segura:
- Verifica si √≠ndices ya existen
- Crea solo los faltantes
- Reporta resultados detallados

**√çndices que agrega:**
1. `idx_apsa_codigo_cmdic` - Para JOINs APSA-ACONEX
2. `idx_aconex_document_no` - Para JOINs ACONEX-APSA
3. `idx_apsa_load_disc` - Queries por load_id + disciplina
4. `idx_apsa_load_subs` - Queries por load_id + subsistema
5. `idx_aconex_load_doc` - Queries ACONEX por load_id + documento
6. `idx_aconex_load_sub` - Queries ACONEX por load_id + subsistema
7. `idx_apsa_load_disc_status` - M√©tricas por disciplina + status
8. `idx_apsa_load_subs_status` - M√©tricas por subsistema + status

**Archivo SQL alternativo:** `backend/migrations/add_performance_indexes.sql`

---

### 4. Queries Optimizadas (Referencia)

**Archivo:** `backend/app/metrics_optimized.py`

Funciones de referencia con diferentes estrategias de optimizaci√≥n:
- `count_error_ss_optimized()` - Versi√≥n con LEFT JOIN
- `count_error_ss_simple()` - Versi√≥n con CTE (Common Table Expression)
- `count_error_ss_with_temp_columns()` - Versi√≥n √≥ptima con columnas pre-calculadas

---

## üìä Estado Actual de los Endpoints

| Endpoint | Queries | Estado | Siguiente Optimizaci√≥n |
|----------|---------|--------|----------------------|
| `/metrics/cards` | 5 | ‚úÖ OPTIMIZADO | Agregar √≠ndices |
| `/metrics/disciplinas` | 40 | ‚ö†Ô∏è N+1 PROBLEM | Reescribir con GROUP BY |
| `/metrics/subsistemas` | 2 | ‚ö†Ô∏è EXISTS lento | Reescribir con LEFT JOIN |
| `/metrics/changes/summary` | 2 | ‚úÖ OK | Posible unificaci√≥n en 1 query |
| `/aconex/duplicates` | 1 | ‚ö†Ô∏è Normalizaci√≥n lenta | Agregar √≠ndices |

**Leyenda:**
- ‚úÖ = Optimizado o rendimiento aceptable
- ‚ö†Ô∏è = Requiere optimizaci√≥n
- üî¥ = Cr√≠tico (>15 segundos)

---

## üéØ Pr√≥ximos Pasos Recomendados

### Paso 1: Probar el Fix Cr√≠tico (AHORA)

```bash
# 1. Reiniciar el backend
cd backend
# Detener el servidor si est√° corriendo (Ctrl+C)
# Iniciar de nuevo
uvicorn app.main:app --reload

# 2. Probar el endpoint
curl http://localhost:8000/metrics/cards \
  -H "Authorization: Bearer YOUR_TOKEN"

# 3. Verificar los logs - deber√≠as ver:
# ‚è±Ô∏è  Count APSA con Error de SS (OPTIMIZADO con LEFT JOIN): X.XXms
```

**Resultado esperado:** Deber√≠a completar en 2-10 segundos en lugar de >15 minutos.

---

### Paso 2: Agregar √çndices (5 minutos)

```bash
# Opci√≥n A: Usar script Python (recomendado)
cd backend
python scripts/add_indexes.py

# Opci√≥n B: Ejecutar SQL manualmente
# Conectar a tu base de datos y ejecutar:
# backend/migrations/add_performance_indexes.sql
```

**Impacto esperado:**
- 40-60% de mejora en queries con JOINs
- 50-80% de mejora en queries con EXISTS

---

### Paso 3: Medir Baseline (10 minutos)

```bash
# 1. Resetear estad√≠sticas
curl -X POST http://localhost:8000/admin/performance/reset \
  -H "Authorization: Bearer YOUR_TOKEN"

# 2. Ejecutar cada endpoint 3-5 veces
for i in {1..5}; do
  curl http://localhost:8000/metrics/cards -H "Authorization: Bearer YOUR_TOKEN"
  curl http://localhost:8000/metrics/disciplinas -H "Authorization: Bearer YOUR_TOKEN"
  curl http://localhost:8000/metrics/subsistemas -H "Authorization: Bearer YOUR_TOKEN"
  curl http://localhost:8000/metrics/changes/summary -H "Authorization: Bearer YOUR_TOKEN"
  curl http://localhost:8000/aconex/duplicates -H "Authorization: Bearer YOUR_TOKEN"
done

# 3. Ver resumen
curl http://localhost:8000/admin/performance/summary \
  -H "Authorization: Bearer YOUR_TOKEN"
```

**Documentar resultados en:** `PERFORMANCE_BASELINE.md`

---

### Paso 4: Optimizar `/metrics/disciplinas` (30 minutos)

**Problema:** Ejecuta 40 queries en un loop (4 queries √ó 10 disciplinas)

**Soluci√≥n:** Reescribir con 2 queries usando GROUP BY

**Impacto esperado:** 90-95% de reducci√≥n en tiempo

**Referencia:** Plan de Optimizaci√≥n - Etapa 2

---

### Paso 5: Optimizar `/metrics/subsistemas` (20 minutos)

**Problema:** 2 queries separadas, una con EXISTS

**Soluci√≥n:** Unificar en 1 query con LEFT JOIN

**Impacto esperado:** 40-60% de reducci√≥n en tiempo

**Referencia:** Plan de Optimizaci√≥n - Etapa 4

---

### Paso 6: (Opcional) Columnas Normalizadas (1 hora)

Si despu√©s de √≠ndices a√∫n hay lentitud por normalizaci√≥n:

1. Agregar columnas:
   - `apsa_protocols.codigo_cmdic_norm`
   - `apsa_protocols.subsistema_norm`
   - `aconex_docs.document_no_norm`
   - `aconex_docs.subsystem_code_norm`

2. Crear triggers para auto-actualizaci√≥n

3. Crear √≠ndices en columnas normalizadas

4. Actualizar queries para usar columnas pre-calculadas

**Impacto esperado:** 80-95% de reducci√≥n adicional

---

## üìà Mejoras Esperadas Totales

Con todos los pasos completados:

| Endpoint | Antes | Despu√©s (estimado) | Mejora |
|----------|-------|-------------------|--------|
| `/metrics/cards` | >15 min | 1-3 seg | 99.7% |
| `/metrics/disciplinas` | 10-30 seg | 0.5-2 seg | 95% |
| `/metrics/subsistemas` | 3-8 seg | 0.5-1.5 seg | 70% |
| `/metrics/changes/summary` | 2-5 seg | 1-2 seg | 50% |
| `/aconex/duplicates` | 1-3 seg | 0.3-0.8 seg | 60% |

**Nota:** Los tiempos "Antes" son estimaciones. Los tiempos reales dependen del tama√±o de tu base de datos.

---

## üêõ Problemas Conocidos

### 1. Normalizaci√≥n en Runtime

**Descripci√≥n:** La funci√≥n `N()` ejecuta 3 REPLACE anidados en cada comparaci√≥n.

**Impacto:** Queries lentas cuando hay muchos registros.

**Soluci√≥n temporal:** ‚úÖ Reducido con subconsultas (ejecuta 1 vez por tabla)

**Soluci√≥n √≥ptima:** Columnas pre-calculadas (Paso 6)

---

### 2. Problema N+1 en `/metrics/disciplinas`

**Descripci√≥n:** Ejecuta 40 queries en un loop.

**Impacto:** ALTO - Este es el segundo problema m√°s grave despu√©s de "Error de SS".

**Soluci√≥n:** Paso 4 (reescribir con GROUP BY)

---

### 3. Subconsultas EXISTS en Varios Endpoints

**Descripci√≥n:** Uso de subconsultas correlacionadas con EXISTS.

**Impacto:** MEDIO - Puede ser lento en tablas grandes.

**Soluci√≥n:** Reescribir con LEFT JOIN (Pasos 4-5)

---

## üìù Archivos Creados/Modificados

### Nuevos Archivos

- `backend/app/timing.py` - Sistema de instrumentaci√≥n
- `backend/app/metrics_optimized.py` - Queries optimizadas de referencia
- `backend/scripts/add_indexes.py` - Script para agregar √≠ndices
- `backend/scripts/__init__.py` - M√≥dulo Python
- `backend/migrations/add_performance_indexes.sql` - √çndices en SQL
- `backend/PERFORMANCE_INSTRUMENTATION.md` - Documentaci√≥n de instrumentaci√≥n
- `backend/OPTIMIZATION_STATUS.md` - Este archivo

### Archivos Modificados

- `backend/app/main.py`:
  - Agregado logging e imports de timing
  - Instrumentados 5 endpoints principales
  - Reescrita query "Error de SS" (l√≠neas 855-898)
  - Agregados 3 endpoints de administraci√≥n de performance

---

## üîß Configuraci√≥n

### Logging

El logging est√° configurado en `backend/app/main.py` l√≠nea 108:

```python
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

Para m√°s detalle, cambiar a `logging.DEBUG`.

### Desactivar Instrumentaci√≥n

Si necesitas desactivar la instrumentaci√≥n temporalmente:

```python
# Comentar decoradores en main.py
# @measure_endpoint("metrics_cards")  # ‚Üê Comentar esta l√≠nea
def metrics_cards(...):
    ...
```

---

## üìû Soporte

Si encuentras problemas:

1. Revisa los logs del servidor
2. Verifica que los √≠ndices se crearon: `python scripts/add_indexes.py`
3. Confirma que el endpoint devuelve resultados (aunque sean lentos)
4. Usa `/admin/performance/stats` para ver d√≥nde est√° el cuello de botella

---

## ‚úÖ Checklist de Verificaci√≥n

Despu√©s de aplicar cada paso, verifica:

- [ ] El servidor inicia sin errores
- [ ] Los endpoints devuelven resultados correctos
- [ ] Los tiempos han mejorado (ver `/admin/performance/summary`)
- [ ] No hay errores en los logs
- [ ] Los √≠ndices se crearon correctamente
- [ ] Las m√©tricas de "Error de SS" son correctas (comparar con versi√≥n anterior si tienes)

---

**√öltima actualizaci√≥n:** 2025-11-17
**Siguiente revisi√≥n:** Despu√©s de completar Paso 3 (baseline)
